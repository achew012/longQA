seed: 1234
lr: 1e-04
clip-norm: 0.1
dropout: 0.2
max-tokens: 4000
warmup: 1000
num_workers: 4
limit_val_batches: 0.005
limit_test_batches: 0.005
limit_train_batches: 0.002
max_output_len: 64
val_every: 0.33
max_input_len: 470
batch_size: 8
eval_batch_size: 8
grad_accum: 1
fp16: False
grad_ckpt: True
attention_window: 256
num_epochs: 15
use_entity_embeddings: False
model_name: allenai/longformer-base-4096 #mrm8488/longformer-base-4096-finetuned-squadv2
trained_model_path: "s3://experiment-logging/storage/LangGen/promptNER-QA-Base.7ffa23a05839464980272aa317353fc3/models/best_ner_model.ckpt"
data_dir: /data
output_dir: ./saved_models/test
clearml_dataset_project_name: datasets/muc4
clearml_dataset_name: muc4-processed
clearml_dataset_tags: ["processed", "GRIT"]
debug: False
train: True
test: True
role_list: ["PerpInd", "PerpOrg", "Target", "Victim", "Weapon"]


# base
# trained_model_path = bucket_ops.get_file(
#     remote_path="s3://experiment-logging/storage/LangGen/promptNER-QA-Base.7ffa23a05839464980272aa317353fc3/models/best_ner_model.ckpt"
# )

# squad-finetune
# trained_model_path = bucket_ops.get_file(
#             remote_path="s3://experiment-logging/storage/LangGen/promptNER-QA-Squad.2bfce82a26464e37a945c4696a8036f6/models/best_ner_model.ckpt"
#             )

# trained_model_path = bucket_ops.get_file(
#             remote_path="s3://experiment-logging/storage/LangGen/MRC-NER-PRETRAINSSPANS.962f18a7e03b4c99a18972f53b667d42/models/best_ner_model.ckpt"
#             )

